{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "  # This notebook splits the data into training, validation and test sets. Also pre-processes the data\n",
    "  Data is split by instance, for each problem set 6 instances are used for training, 2 for validation, and 1 for testing"
   ],
   "id": "dc9c5ec046eee87c"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T13:51:18.643762Z",
     "start_time": "2025-05-03T13:51:18.631544Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:51:18.124594Z",
     "start_time": "2025-05-03T13:51:17.956785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "column_names = [\n",
    "    'iterations',\n",
    "    'instance_type',\n",
    "    'tw_spread',\n",
    "    'operator_selection_mechanism',\n",
    "    'number_of_vertices_to_remove',\n",
    "    \"delta_last_improv\", #change to rel_delta... for future work when i want to test on my benchmarks\n",
    "    \"acceptance_ratio\",\n",
    "    \"i_last_improv\",\n",
    "    'prev_remove_operator',\n",
    "    'prev_insert_operator',\n",
    "    'route_imbalance',\n",
    "    'capacity_utilization',\n",
    "    'success_r_op_1',\n",
    "    'success_r_op_2',\n",
    "    'success_r_op_3',\n",
    "    'success_r_op_4',\n",
    "    'success_r_op_5',\n",
    "    'success_i_op_1',\n",
    "    'success_i_op_2',\n",
    "    'success_i_op_3',\n",
    "    'delta_cost',\n",
    "    'new_cost',\n",
    "    'chosen_remove_operator',\n",
    "    'chosen_insert_operator'\n",
    "]\n",
    "\n",
    "\n",
    "log_df = pd.read_csv(\"../../results_and_logs/training_alns_iterations_1.log\", sep=',', header=None, names=column_names)"
   ],
   "id": "88ac366be1dfbb09",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T13:51:23.646190Z",
     "start_time": "2025-05-03T13:51:23.615148Z"
    }
   },
   "cell_type": "code",
   "source": "log_df['iterations'] = log_df['iterations'].apply(lambda x: int(str(x).split(\":\")[-1]))",
   "id": "a828612797176c6d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:01:00.902802Z",
     "start_time": "2025-05-02T10:01:00.881349Z"
    }
   },
   "cell_type": "code",
   "source": "log_df['current_cost'] = log_df['new_cost'] - log_df['delta_cost']",
   "id": "da710a53d8b1d6a2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:01:02.473811Z",
     "start_time": "2025-05-02T10:01:02.461156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#relativise delta last improv:\n",
    "log_df['rel_delta_last_improv'] = log_df['delta_last_improv'] / log_df['current_cost']"
   ],
   "id": "dcdf56701cf01949",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T08:45:19.776879Z",
     "start_time": "2025-05-02T08:45:19.749840Z"
    }
   },
   "cell_type": "code",
   "source": "log_df[['delta_last_improv', 'current_cost', 'rel_delta_last_improv']].head()",
   "id": "675ef10ed1d5aede",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   delta_last_improv  current_cost  rel_delta_last_improv\n",
       "0           0.000000  10267.032510               0.000000\n",
       "1        -718.948672   9548.083839              -0.075298\n",
       "2         -91.810910   9456.272928              -0.009709\n",
       "3        -160.354919   9295.918009              -0.017250\n",
       "4        -160.354919   9295.918009              -0.017250"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_last_improv</th>\n",
       "      <th>current_cost</th>\n",
       "      <th>rel_delta_last_improv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10267.032510</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-718.948672</td>\n",
       "      <td>9548.083839</td>\n",
       "      <td>-0.075298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-91.810910</td>\n",
       "      <td>9456.272928</td>\n",
       "      <td>-0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-160.354919</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>-0.017250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-160.354919</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>-0.017250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:48:38.981798Z",
     "start_time": "2025-05-01T11:48:38.966710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_short_long_term_improvement(df, alpha, k):\n",
    "    improvements = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        current_cost = df.loc[i, 'current_cost']\n",
    "        immediate = df.loc[i, 'delta_cost']\n",
    "        future_window = df['delta_cost'].iloc[i+1:i+1+k]\n",
    "\n",
    "        # Best improvement (most negative value) in the next k steps\n",
    "        best_future_improvement = future_window.min() if not future_window.empty else 0\n",
    "\n",
    "        # Weighted combination\n",
    "        rel_immediate = immediate / current_cost #added\n",
    "        rel_best_future_improvement = best_future_improvement / current_cost #added\n",
    "        combined = alpha * rel_immediate + (1 - alpha) * rel_best_future_improvement\n",
    "        improvements.append(combined)\n",
    "\n",
    "    df['short_long_improvement'] = improvements\n",
    "    return df"
   ],
   "id": "165e1f19bfeb922e",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:49:17.079390Z",
     "start_time": "2025-05-01T11:48:48.298017Z"
    }
   },
   "cell_type": "code",
   "source": "df = compute_short_long_term_improvement(log_df, alpha=0.5, k=10)",
   "id": "6641434a83f81abe",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:18:25.964652Z",
     "start_time": "2025-05-01T11:18:25.890159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.count()\n",
    "# all columns are complete except for pre_remove_operator and prev_insert_operator since the first iteration in every alns run has no previous values"
   ],
   "id": "a35943fe4b64c97c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterations                      216000\n",
       "instance_type                   216000\n",
       "tw_spread                       216000\n",
       "operator_selection_mechanism    216000\n",
       "number_of_vertices_to_remove    216000\n",
       "delta_last_improv               216000\n",
       "acceptance_ratio                216000\n",
       "i_last_improv                   216000\n",
       "prev_remove_operator            215892\n",
       "prev_insert_operator            215892\n",
       "route_imbalance                 216000\n",
       "capacity_utilization            216000\n",
       "success_r_op_1                  216000\n",
       "success_r_op_2                  216000\n",
       "success_r_op_3                  216000\n",
       "success_r_op_4                  216000\n",
       "success_r_op_5                  216000\n",
       "success_i_op_1                  216000\n",
       "success_i_op_2                  216000\n",
       "success_i_op_3                  216000\n",
       "delta_cost                      216000\n",
       "new_cost                        216000\n",
       "chosen_remove_operator          216000\n",
       "chosen_insert_operator          216000\n",
       "current_cost                    216000\n",
       "rel_delta_last_improv           216000\n",
       "short_long_improvement          216000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:50:14.434242Z",
     "start_time": "2025-05-01T11:50:14.417902Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "9bf59ddb90aef8ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216000, 27)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting in train, validation and test sets",
   "id": "4db4412f88670887"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:50:22.270018Z",
     "start_time": "2025-05-01T11:50:22.263128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "problem_types = 6\n",
    "problem_instances = 9\n",
    "runs_per_instance = 2\n",
    "iterations_per_run = 2000"
   ],
   "id": "80c273deeee0fb90",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:50:58.185060Z",
     "start_time": "2025-05-01T11:50:58.093919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. divide dataframe by problem types\n",
    "training_set, validation_set, test_set = [], [], []\n",
    "problem_size = problem_instances * runs_per_instance * iterations_per_run\n",
    "for start in range(0, df.shape[0], problem_size):\n",
    "    print(\" / problem type start: \", start)\n",
    "    df_by_problem_type = df.iloc[start:start + problem_size]\n",
    "    # divide in two, first part was done using roulette-wheel, second part was done using random selector\n",
    "    df_roulette_wheel = df_by_problem_type.iloc[0:18000]\n",
    "    df_random = df_by_problem_type.iloc[18000:]\n",
    "    # from each problem type take three instances - two for validation and one for testing\n",
    "    # training sets:\n",
    "    df_roulette_wheel_train = df_roulette_wheel.iloc[0:2000*6]\n",
    "    df_random_train = df_random.iloc[0:2000*6]\n",
    "    # validation sets:\n",
    "    df_roulette_wheel_val = df_roulette_wheel.iloc[2000*6:2000*8]\n",
    "    df_random_val = df_random.iloc[2000*6:2000*8]\n",
    "    # testing sets:\n",
    "    df_roulette_wheel_test = df_roulette_wheel.iloc[2000*8:]\n",
    "    df_random_test = df_random.iloc[2000*8:]\n",
    "\n",
    "    print(\"train length of both operator selectors: \", df_roulette_wheel_train.shape[0], df_random_train.shape[0])\n",
    "    print(\"validation length of both operator selectors: \", df_roulette_wheel_val.shape[0], df_random_val.shape[0])\n",
    "    print(\"test length of both operator selectors: \", df_roulette_wheel_test.shape[0], df_random_test.shape[0])\n",
    "\n",
    "    training_subset = pd.concat([df_roulette_wheel_train, df_random_train])\n",
    "    training_set.append(training_subset)\n",
    "\n",
    "    validation_subset = pd.concat([df_roulette_wheel_val, df_random_val])\n",
    "    validation_set.append(validation_subset)\n",
    "\n",
    "    test_subset = pd.concat([df_roulette_wheel_test, df_random_test])\n",
    "    training_set.append(test_subset) #todo: i changed to the training subset so it has more data to train with\n",
    "\n",
    "    # process_data(df_subset)"
   ],
   "id": "62b41363375696dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " / problem type start:  0\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n",
      " / problem type start:  36000\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n",
      " / problem type start:  72000\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n",
      " / problem type start:  108000\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n",
      " / problem type start:  144000\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n",
      " / problem type start:  180000\n",
      "train length of both operator selectors:  12000 12000\n",
      "validation length of both operator selectors:  4000 4000\n",
      "test length of both operator selectors:  2000 2000\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:51:27.683139Z",
     "start_time": "2025-05-01T11:51:27.630121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_set   = pd.concat(training_set, ignore_index=True)\n",
    "validation_set = pd.concat(validation_set,   ignore_index=True)\n",
    "#test_set       = pd.concat(test_set,  ignore_index=True)"
   ],
   "id": "197629f81e2ae6e6",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:51:29.287729Z",
     "start_time": "2025-05-01T11:51:29.277449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(training_set.shape)\n",
    "print(validation_set.shape)\n",
    "# print(test_set.shape)"
   ],
   "id": "49df5304d556fb72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168000, 27)\n",
      "(48000, 27)\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:58:24.087442Z",
     "start_time": "2025-05-01T11:58:15.199031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_set.to_csv('training_set_2.csv', header=True, index=False)\n",
    "validation_set.to_csv('validation_set_2.csv', header=True, index=False)\n",
    "#test_set.to_csv('test_set.csv', header=True, index=False)"
   ],
   "id": "b7797557427f6760",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:45:18.765779Z",
     "start_time": "2025-05-01T11:45:16.367945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(training_set[[\"short_long_improvement\"]])\n",
    "training_set[\"y_scaled\"] = scaler.transform(training_set[[\"short_long_improvement\"]])"
   ],
   "id": "d1ef538f34bb841",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:44:48.184173Z",
     "start_time": "2025-05-01T11:44:48.135533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group data that belongs to the same state\n",
    "same_state_cols = [\"instance_type\",\"tw_spread\", \"chosen_remove_operator\", \"chosen_insert_operator\"]\n",
    "grp_same_state = training_set.groupby(same_state_cols)\n",
    "print(\"number of groups= \", grp_same_state.ngroups)\n",
    "# for a total of 144,000 entries in training_set, 105442 groups were created, which means, there are not many entries that share the same state"
   ],
   "id": "23cf07ac233f40af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of groups=  90\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:45:21.376321Z",
     "start_time": "2025-05-01T11:45:21.342155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "noise_var  = grp_same_state[\"y_scaled\"].var().mean()      # σ²_noise\n",
    "print(noise_var)"
   ],
   "id": "60e75286a5309ba3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8446677456447272\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:45:25.402556Z",
     "start_time": "2025-05-01T11:45:25.385921Z"
    }
   },
   "cell_type": "code",
   "source": "training_set[\"y_scaled\"].var()",
   "id": "a2b0ad6cbc91bf6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0000059524163836)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare scalers for the data",
   "id": "ea374385758cc503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:45:49.403190Z",
     "start_time": "2025-05-01T11:45:49.368064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler"
   ],
   "id": "27da02884b02d122",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T11:45:51.898441Z",
     "start_time": "2025-05-01T11:45:50.837141Z"
    }
   },
   "cell_type": "code",
   "source": "train_df = pd.read_csv(\"training_set.csv\")",
   "id": "5cf07d113ebe57e7",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T19:21:07.721314Z",
     "start_time": "2025-04-26T19:21:07.677785Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.head()\n",
   "id": "c711a976a76379b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   iterations  instance_type  tw_spread  operator_selection_mechanism  \\\n",
       "0           1              0          1                             1   \n",
       "1           2              0          1                             1   \n",
       "2           3              0          1                             1   \n",
       "3           4              0          1                             1   \n",
       "4           5              0          1                             1   \n",
       "\n",
       "   number_of_vertices_to_remove  delta_last_improv  acceptance_ratio  \\\n",
       "0                            15           0.000000               0.0   \n",
       "1                             5        -718.948672               1.0   \n",
       "2                             5         -91.810910               1.0   \n",
       "3                             5        -160.354919               1.0   \n",
       "4                             5        -160.354919               1.0   \n",
       "\n",
       "   i_last_improv  prev_remove_operator  prev_insert_operator  ...  \\\n",
       "0              0                   NaN                   NaN  ...   \n",
       "1              0                   1.0                   2.0  ...   \n",
       "2              0                   1.0                   3.0  ...   \n",
       "3              0                   4.0                   1.0  ...   \n",
       "4              1                   5.0                   2.0  ...   \n",
       "\n",
       "   success_i_op_1  success_i_op_2  success_i_op_3  delta_cost     new_cost  \\\n",
       "0             1.0             1.0             1.0 -718.948672  9548.083839   \n",
       "1             1.0             1.0             1.0  -91.810910  9456.272928   \n",
       "2             1.0             1.0             1.0 -160.354919  9295.918009   \n",
       "3             1.0             1.0             1.0    0.000000  9295.918009   \n",
       "4             1.0             1.0             1.0    0.000000  9295.918009   \n",
       "\n",
       "   chosen_remove_operator  chosen_insert_operator  current_cost  \\\n",
       "0                       1                       2  10267.032510   \n",
       "1                       1                       3   9548.083839   \n",
       "2                       4                       1   9456.272928   \n",
       "3                       5                       2   9295.918009   \n",
       "4                       3                       1   9295.918009   \n",
       "\n",
       "   rel_delta_last_improv  short_long_improvement  \n",
       "0               0.000000               -0.054251  \n",
       "1              -0.075298               -0.012359  \n",
       "2              -0.009709               -0.017553  \n",
       "3              -0.017250               -0.005781  \n",
       "4              -0.017250               -0.005781  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>tw_spread</th>\n",
       "      <th>operator_selection_mechanism</th>\n",
       "      <th>number_of_vertices_to_remove</th>\n",
       "      <th>delta_last_improv</th>\n",
       "      <th>acceptance_ratio</th>\n",
       "      <th>i_last_improv</th>\n",
       "      <th>prev_remove_operator</th>\n",
       "      <th>prev_insert_operator</th>\n",
       "      <th>...</th>\n",
       "      <th>success_i_op_1</th>\n",
       "      <th>success_i_op_2</th>\n",
       "      <th>success_i_op_3</th>\n",
       "      <th>delta_cost</th>\n",
       "      <th>new_cost</th>\n",
       "      <th>chosen_remove_operator</th>\n",
       "      <th>chosen_insert_operator</th>\n",
       "      <th>current_cost</th>\n",
       "      <th>rel_delta_last_improv</th>\n",
       "      <th>short_long_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-718.948672</td>\n",
       "      <td>9548.083839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10267.032510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.054251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-718.948672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-91.810910</td>\n",
       "      <td>9456.272928</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9548.083839</td>\n",
       "      <td>-0.075298</td>\n",
       "      <td>-0.012359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-91.810910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-160.354919</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9456.272928</td>\n",
       "      <td>-0.009709</td>\n",
       "      <td>-0.017553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-160.354919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>-0.017250</td>\n",
       "      <td>-0.005781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-160.354919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9295.918009</td>\n",
       "      <td>-0.017250</td>\n",
       "      <td>-0.005781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T19:35:17.274156Z",
     "start_time": "2025-04-26T19:35:17.004879Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts/feature_prep.joblib']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66,
   "source": [
    "# Prepare scaler for input features\n",
    "num_pos    = [\"iterations\", \"acceptance_ratio\", \"number_of_vertices_to_remove\", \"i_last_improv\", \"route_imbalance\", \"capacity_utilization\", 'success_r_op_1', 'success_r_op_2', 'success_r_op_3', 'success_r_op_4', 'success_r_op_5', 'success_i_op_1', 'success_i_op_2','success_i_op_3']      # always positive\n",
    "\n",
    "num_signed = [\"rel_delta_last_improv\"]           # can be positive or negative\n",
    "\n",
    "cat_cols   = [\"instance_type\", \"tw_spread\", \"operator_selection_mechanism\",\n",
    "              \"prev_remove_operator\", \"prev_insert_operator\"]             # categorical columns\n",
    "\n",
    "# ❶  feature transformer (dense output for easy → torch)\n",
    "prep = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"pos\",    StandardScaler(), num_pos),\n",
    "            (\"signed\", StandardScaler(), num_signed),\n",
    "            (\"cat\",    OneHotEncoder(sparse_output=False,\n",
    "                                     handle_unknown=\"ignore\"), cat_cols),\n",
    "        ])\n",
    "\n",
    "prep.fit(train_df[num_pos + num_signed + cat_cols])\n",
    "joblib.dump(prep, \"../../artifacts/feature_prep.joblib\")"
   ],
   "id": "ccdb7d87a0f55e79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T19:38:11.310211Z",
     "start_time": "2025-04-26T19:38:11.241970Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts/y_scaler.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68,
   "source": [
    "# prepare scaler for target feature\n",
    "y_scaler = StandardScaler().fit(\n",
    "              train_df[[\"short_long_improvement\"]])\n",
    "\n",
    "joblib.dump(y_scaler, \"../../artifacts/y_scaler.joblib\")"
   ],
   "id": "5f7ae897cc8bd334"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
